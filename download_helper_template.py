 import os
import shutil
import sys
from pathlib import Path

# ================================
# é…ç½®åŒºåŸŸ - ä¿®æ”¹æ­¤éƒ¨åˆ†ä»¥é€‚é…ä¸åŒæ’ä»¶
# ================================

# æ’ä»¶åç§°å’Œæè¿°
PLUGIN_NAME = "Joy Caption Two"
PLUGIN_DESCRIPTION = "Joy Caption Alpha Two å›¾åƒæè¿°ç”Ÿæˆæ’ä»¶"

# å®šä¹‰æ¨¡å‹åŠå…¶ä¸‹è½½URLå’Œç›®æ ‡è·¯å¾„
# æ ¼å¼è¯´æ˜ï¼š
# - name: æ¨¡å‹çš„æ˜¾ç¤ºåç§°
# - foreign_url: HuggingFaceåŸå§‹é“¾æ¥
# - domestic_url: HF-Mirroré•œåƒé“¾æ¥ï¼ˆå¦‚æœæ²¡æœ‰é•œåƒï¼Œå¯ä»¥ä½¿ç”¨ç›¸åŒçš„é“¾æ¥ï¼‰
# - target_path: åœ¨ComfyUIä¸­çš„ç›®æ ‡è·¯å¾„ï¼ˆç›¸å¯¹äºComfyUIæ ¹ç›®å½•ï¼‰
# - download_folder: ä¸‹è½½åçš„æ–‡ä»¶å¤¹åç§°ï¼ˆé€šå¸¸æ˜¯å‹ç¼©åŒ…è§£å‹åçš„æ–‡ä»¶å¤¹åï¼‰
MODELS = [
    {
        "name": "google/siglip-so400m-patch14-384",
        "foreign_url": "https://huggingface.co/google/siglip-so400m-patch14-384",
        "domestic_url": "https://hf-mirror.com/google/siglip-so400m-patch14-384",
        "target_path": "models/clip/siglip-so400m-patch14-384",
        "download_folder": "siglip-so400m-patch14-384"
    },
    {
        "name": "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        "foreign_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        "domestic_url": "https://hf-mirror.com/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        "target_path": "models/LLM/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
        "download_folder": "Meta-Llama-3.1-8B-Instruct-bnb-4bit"
    },
    {
        "name": "unsloth/Meta-Llama-3.1-8B-Instruct",
        "foreign_url": "https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct",
        "domestic_url": "https://hf-mirror.com/unsloth/Meta-Llama-3.1-8B-Instruct",
        "target_path": "models/LLM/Meta-Llama-3.1-8B-Instruct",
        "download_folder": "Meta-Llama-3.1-8B-Instruct"
    },
    {
        "name": "Joy-Caption-alpha-two",
        "foreign_url": "https://huggingface.co/spaces/fancyfeast/joy-caption-alpha-two/tree/main/cgrkzexw-599808",
        "domestic_url": "https://huggingface.co/spaces/fancyfeast/joy-caption-alpha-two/tree/main/cgrkzexw-599808",
        "target_path": "models/Joy_caption_two",
        "download_folder": "joy-caption-alpha-two"
    }
]

# æ˜¯å¦å¯ç”¨æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€åŠŸèƒ½
ENABLE_BROWSER_OPEN = True

# å¤§æ–‡ä»¶é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶ä¼šæ˜¾ç¤ºå•ç‹¬çš„è¿›åº¦æ¡ï¼Œå•ä½ï¼šå­—èŠ‚ï¼‰
LARGE_FILE_THRESHOLD = 50 * 1024 * 1024  # 50MB

# ================================
# ä»¥ä¸‹ä»£ç æ— éœ€ä¿®æ”¹
# ================================

# å°è¯•å¯¼å…¥tqdmï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨å®‰è£…
try:
    from tqdm import tqdm
except ImportError:
    print("æ­£åœ¨å®‰è£…tqdmè¿›åº¦æ¡åº“...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "tqdm"])
    from tqdm import tqdm

# å°è¯•å¯¼å…¥DrissionPageï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨å®‰è£…
if ENABLE_BROWSER_OPEN:
    try:
        from DrissionPage import ChromiumPage
    except ImportError:
        print("æ­£åœ¨å®‰è£…DrissionPageåº“...")
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "DrissionPage"])
        from DrissionPage import ChromiumPage

def print_download_links():
    """æ‰“å°æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥"""
    print(f"=== {PLUGIN_NAME} æ¨¡å‹ä¸‹è½½é“¾æ¥ ===")
    print(f"{PLUGIN_DESCRIPTION}")
    print("è¯·ä½¿ç”¨æ‚¨å–œæ¬¢çš„ä¸‹è½½å·¥å…·(å¦‚è¿…é›·)ä¸‹è½½ä»¥ä¸‹æ¨¡å‹:")
    print()
    
    print("æ¨¡å‹åç§°ï¼š")
    for model in MODELS:
        print(f"  â€¢ {model['name']}")
    
    print("\nHuggingFaceé“¾æ¥:")
    for model in MODELS:
        print(f"  {model['foreign_url']}")
    
    print("\nHF-Mirroré“¾æ¥ï¼š")
    for model in MODELS:
        print(f"  {model['domestic_url']}")
    
    print("\nComfyUIç›®æ ‡è·¯å¾„:")
    for model in MODELS:
        print(f"  {model['target_path']}")
    
    print("\nä¸‹è½½å®Œæˆåï¼Œä½¿ç”¨æ­¤è„šæœ¬å°†æ–‡ä»¶ç§»åŠ¨åˆ°æ­£ç¡®ä½ç½®ã€‚")
    print()

def get_dir_size(path):
    """è®¡ç®—ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æ€»å¤§å°"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            if not os.path.islink(fp):
                total_size += os.path.getsize(fp)
    return total_size

def copy_with_progress(src, dst):
    """å¸¦è¿›åº¦æ¡çš„æ–‡ä»¶å¤åˆ¶"""
    file_size = os.path.getsize(src)
    with tqdm(total=file_size, unit='B', unit_scale=True, desc=f"å¤åˆ¶ {os.path.basename(src)}") as pbar:
        with open(src, 'rb') as fsrc:
            with open(dst, 'wb') as fdst:
                copied = 0
                while True:
                    buf = fsrc.read(1024*1024)  # 1MBå—
                    if not buf:
                        break
                    fdst.write(buf)
                    copied += len(buf)
                    pbar.update(len(buf))

def copy_tree_with_progress(src, dst):
    """å¸¦è¿›åº¦æ¡çš„ç›®å½•æ ‘å¤åˆ¶"""
    if not os.path.exists(dst):
        os.makedirs(dst)
    
    items = os.listdir(src)
    for item in tqdm(items, desc=f"{os.path.basename(src)}ä¸­çš„æ–‡ä»¶"):
        src_item = os.path.join(src, item)
        dst_item = os.path.join(dst, item)
        
        if os.path.isdir(src_item):
            if os.path.exists(dst_item):
                shutil.rmtree(dst_item)
            print(f"å¤åˆ¶ç›®å½•: {item}")
            shutil.copytree(src_item, dst_item)
        else:
            # å¯¹äºå¤§æ–‡ä»¶ï¼Œæ˜¾ç¤ºå•ç‹¬çš„è¿›åº¦æ¡
            if os.path.getsize(src_item) > LARGE_FILE_THRESHOLD:
                copy_with_progress(src_item, dst_item)
            else:
                shutil.copy2(src_item, dst_item)

def open_hf_mirror_links():
    """ä½¿ç”¨DrissionPageæ‰“å¼€æ‰€æœ‰hf-mirroré“¾æ¥"""
    if not ENABLE_BROWSER_OPEN:
        print("æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€åŠŸèƒ½å·²ç¦ç”¨ã€‚")
        return
        
    try:
        print("\næ­£åœ¨æ‰“å¼€æµè§ˆå™¨å¹¶åŠ è½½ä¸‹è½½é“¾æ¥...")
        
        # åˆ›å»ºæµè§ˆå™¨é¡µé¢å¯¹è±¡
        page = ChromiumPage()
        
        # æ‰“å¼€ç¬¬ä¸€ä¸ªé“¾æ¥
        first_model = MODELS[0]
        print(f"æ‰“å¼€ç¬¬ä¸€ä¸ªé“¾æ¥: {first_model['name']}")
        page.get(first_model['domestic_url'])
        
        # ä¸ºå…¶ä½™é“¾æ¥åˆ›å»ºæ–°æ ‡ç­¾é¡µ
        for model in MODELS[1:]:
            print(f"åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€: {model['name']}")
            new_tab = page.new_tab()
            new_tab.get(model['domestic_url'])
        
        print("æ‰€æœ‰ä¸‹è½½é“¾æ¥å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ã€‚")
        print("æ‚¨å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹å’Œä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚")
        
    except Exception as e:
        print(f"æ‰“å¼€æµè§ˆå™¨é“¾æ¥æ—¶å‡ºé”™: {e}")
        print("æ‚¨å¯ä»¥æ‰‹åŠ¨å¤åˆ¶ä»¥ä¸‹é“¾æ¥åˆ°æµè§ˆå™¨ä¸­:")
        for model in MODELS:
            print(f"  {model['domestic_url']}")

def move_model_files(download_path, comfyui_path):
    """å°†æ¨¡å‹æ–‡ä»¶ä»ä¸‹è½½ä½ç½®ç§»åŠ¨åˆ°ComfyUI"""
    # è·å–å¯ç”¨çš„æ¨¡å‹ï¼ˆå­˜åœ¨çš„ç›®å½•ï¼‰
    available_models = []
    for model in MODELS:
        source_dir = os.path.join(download_path, model["download_folder"])
        if os.path.exists(source_dir):
            available_models.append(model)
        else:
            print(f"è­¦å‘Š: æºç›®å½• {source_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡...")
    
    if not available_models:
        print("åœ¨ä¸‹è½½è·¯å¾„ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ç›®å½•ã€‚")
        print("è¯·ç¡®ä¿å·²ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¹¶è§£å‹åˆ°æ­£ç¡®çš„æ–‡ä»¶å¤¹åç§°ã€‚")
        print("\næœŸæœ›çš„æ–‡ä»¶å¤¹åç§°:")
        for model in MODELS:
            print(f"  â€¢ {model['download_folder']}")
        return
    
    # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹çš„è¿›åº¦
    for i, model in enumerate(available_models):
        source_dir = os.path.join(download_path, model["download_folder"])
        target_dir = os.path.join(comfyui_path, model["target_path"])
        
        # å¦‚æœç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        os.makedirs(target_dir, exist_ok=True)
        
        print(f"\n[{i+1}/{len(available_models)}] ç§»åŠ¨ {model['name']} æ–‡ä»¶")
        print(f"ä»: {source_dir}")
        print(f"åˆ°: {target_dir}")
        
        # è·å–ç›®å½•å¤§å°ä»¥ä¾¿æ›´å¥½åœ°æŠ¥å‘Šè¿›åº¦
        dir_size = get_dir_size(source_dir)
        print(f"æ€»å¤§å°: {dir_size / (1024*1024*1024):.2f} GB")
        
        # ä½¿ç”¨è¿›åº¦æ¡å¤åˆ¶æ–‡ä»¶
        copy_tree_with_progress(source_dir, target_dir)
        
        print(f"âœ“ æˆåŠŸç§»åŠ¨ {model['name']} åˆ° {target_dir}")

def main():
    print(f"=== {PLUGIN_NAME} ä¸‹è½½åŠ©æ‰‹ ===")
    print(f"{PLUGIN_DESCRIPTION}")
    print()
    
    # é¦–å…ˆæ˜¾ç¤ºä¸‹è½½é“¾æ¥
    print_download_links()
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦ç»§ç»­ç§»åŠ¨æ–‡ä»¶
    proceed = input("æ˜¯å¦ç»§ç»­ç§»åŠ¨ä¸‹è½½çš„æ–‡ä»¶? (y/n): ").strip().lower()
    
    if proceed != 'y':
        print("é€€å‡ºã€‚å½“æ‚¨å‡†å¤‡å¥½ç§»åŠ¨æ–‡ä»¶æ—¶ï¼Œå¯ä»¥å†æ¬¡è¿è¡Œæ­¤è„šæœ¬ã€‚")
        return
    
    # æ‰“å¼€ä¸‹è½½é“¾æ¥
    if ENABLE_BROWSER_OPEN:
        open_browser = input("æ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä¸‹è½½é“¾æ¥? (y/n): ").strip().lower()
        if open_browser == 'y':
            open_hf_mirror_links()
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦å·²å®Œæˆä¸‹è½½
            download_complete = input("\nä¸‹è½½å®Œæˆåï¼Œæ˜¯å¦ç»§ç»­ç§»åŠ¨æ–‡ä»¶åˆ°ComfyUIç›®å½•? (y/n): ").strip().lower()
            if download_complete != 'y':
                print("æ‚¨å¯ä»¥ç¨åå†æ¬¡è¿è¡Œæ­¤è„šæœ¬æ¥ç§»åŠ¨æ–‡ä»¶ã€‚")
                return
    
    # ä»ç”¨æˆ·è¾“å…¥è·å–è·¯å¾„
    download_path = input("è¾“å…¥æ‚¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„: ").strip()
    comfyui_path = input("è¾“å…¥æ‚¨çš„ComfyUIå®‰è£…è·¯å¾„: ").strip()
    
    # å¦‚æœç”¨æˆ·å¤åˆ¶äº†å¸¦å¼•å·çš„è·¯å¾„ï¼Œå»é™¤å¼•å·
    download_path = download_path.strip('"\'')
    comfyui_path = comfyui_path.strip('"\'')
    
    # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(download_path):
        print(f"é”™è¯¯: ä¸‹è½½è·¯å¾„ {download_path} ä¸å­˜åœ¨ã€‚")
        return
    
    if not os.path.exists(comfyui_path):
        print(f"é”™è¯¯: ComfyUIè·¯å¾„ {comfyui_path} ä¸å­˜åœ¨ã€‚")
        return
    
    # ç§»åŠ¨æ–‡ä»¶
    move_model_files(download_path, comfyui_path)
    print(f"\nğŸ‰ {PLUGIN_NAME} æ‰€æœ‰æ–‡ä»¶å·²æˆåŠŸç§»åŠ¨ï¼")
    input("æŒ‰å›è½¦é”®é€€å‡º...")

if __name__ == "__main__":
    main()